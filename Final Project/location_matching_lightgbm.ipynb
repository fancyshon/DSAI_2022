{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T12:48:23.002329Z","iopub.status.busy":"2022-05-30T12:48:23.001867Z","iopub.status.idle":"2022-05-30T12:48:24.529043Z","shell.execute_reply":"2022-05-30T12:48:24.528263Z","shell.execute_reply.started":"2022-05-30T12:48:23.002276Z"},"id":"H5QntWoelAkH","outputId":"31efe7df-24ff-40e8-8517-0c7174968413","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\User\\.virtualenvs\\HW3-9xnMMrK4\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"ename":"ModuleNotFoundError","evalue":"No module named 'seaborn'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32mc:\\Users\\User\\Desktop\\DSAI_2022\\Final Project\\location_matching_lightgbm.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/DSAI_2022/Final%20Project/location_matching_lightgbm.ipynb#ch0000000?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m GroupKFold, KFold, StratifiedKFold\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/DSAI_2022/Final%20Project/location_matching_lightgbm.ipynb#ch0000000?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/DSAI_2022/Final%20Project/location_matching_lightgbm.ipynb#ch0000000?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/DSAI_2022/Final%20Project/location_matching_lightgbm.ipynb#ch0000000?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/DSAI_2022/Final%20Project/location_matching_lightgbm.ipynb#ch0000000?line=12'>13</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","import os\n","import gc\n","import random\n","from glob import glob\n","from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n","import warnings\n","import seaborn as sns\n","import pickle\n","import json\n","import re\n","import time\n","import sys\n","from requests import get\n","import multiprocessing\n","import joblib\n","\n","class CFG:\n","    seed = 46\n","    target = \"point_of_interest\"\n","    n_neighbors = 10\n","    n_splits = 3\n","\n","    expID = \"\"\n","    if \"google.colab\" in sys.modules:\n","        expID = get(\"http://172.28.0.2:9000/api/sessions\").json()[0][\"name\"].split(\".\")[0]\n","\n","random.seed(CFG.seed)\n","os.environ[\"PYTHONHASHSEED\"] = str(CFG.seed)\n","np.random.seed(CFG.seed)\n","\n","plt.rcParams[\"font.size\"] = 13\n","warnings.filterwarnings('ignore')\n","\n","# %cd /content/drive/MyDrive/kaggle/foursquare-location-matching/{CFG.expID}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T12:48:24.531508Z","iopub.status.busy":"2022-05-30T12:48:24.53056Z","iopub.status.idle":"2022-05-30T12:48:35.344529Z","shell.execute_reply":"2022-05-30T12:48:35.343418Z","shell.execute_reply.started":"2022-05-30T12:48:24.531447Z"},"id":"wz7JepVilAkN","outputId":"0652de28-9bd3-4ab7-c97c-55e6e11935e6","trusted":true},"outputs":[],"source":["train = pd.read_csv(\"../input/foursquare-location-matching/train.csv\")\n","test = pd.read_csv(\"../input/foursquare-location-matching/test.csv\")\n","test[CFG.target] = \"TEST\"\n","\n","train.head(1)"]},{"cell_type":"markdown","metadata":{"id":"lO9c6tIe3j4B"},"source":["# Devide Train Data into about 600KÃ—2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T12:48:35.346995Z","iopub.status.busy":"2022-05-30T12:48:35.346707Z","iopub.status.idle":"2022-05-30T12:48:43.428738Z","shell.execute_reply":"2022-05-30T12:48:43.427776Z","shell.execute_reply.started":"2022-05-30T12:48:35.346963Z"},"id":"U6PcXKsn3pcK","outputId":"948a4da0-23b5-4716-8a00-1afa3eb5a20b","trusted":true},"outputs":[],"source":["kf = GroupKFold(n_splits=2)\n","for i, (trn_idx, val_idx) in enumerate(kf.split(train, train[CFG.target], train[CFG.target])):\n","    train.loc[val_idx, \"set\"] = i\n","train[\"set\"].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"9yJIRkRD3jr-"},"source":["# Search Candidates"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T12:48:43.430568Z","iopub.status.busy":"2022-05-30T12:48:43.430265Z"},"id":"rsyHcuGDlAkO","outputId":"67bbd8fb-5f0b-4853-ffc3-3421212c1683","trusted":true},"outputs":[],"source":["from sklearn.neighbors import KNeighborsRegressor\n","\n","def add_neighbor_features(df):\n","    dfs = []\n","    columns = ['id', 'name', 'address', 'city', 'state',\n","           'zip', 'country', 'url', 'phone', 'categories']\n","    for c in columns:\n","        if c != \"id\":\n","            df[c] = df[c].astype(str).str.lower()\n","\n","    for country, country_df in tqdm(df.groupby(\"country\")):\n","        country_df = country_df.reset_index(drop=True)\n","        \n","        knn = KNeighborsRegressor(n_neighbors=min(len(country_df), CFG.n_neighbors), \n","                                  metric='haversine', n_jobs=-1)\n","        knn.fit(country_df[['latitude','longitude']], country_df.index)\n","        dists, nears = knn.kneighbors(country_df[['latitude','longitude']], return_distance=True)\n","\n","        targets = country_df[CFG.target].values\n","        for i in range(min(len(country_df), CFG.n_neighbors)):\n","            country_df[f\"d_near_{i}\"] = dists[:, i]\n","            country_df[f\"near_target_{i}\"] = targets[nears[:, i]]\n","            for c in columns:\n","                country_df[f\"near_{c}_{i}\"] = country_df[c].values[nears[:, i]]\n","\n","        for i in range(min(len(country_df), CFG.n_neighbors), CFG.n_neighbors):\n","            country_df[f\"d_near_{i}\"] = np.nan\n","            country_df[f\"near_target_{i}\"] = np.nan\n","            for c in columns:\n","                country_df[f\"near_{c}_{i}\"] = np.nan\n","\n","        dfs.append(country_df)\n","    df = pd.concat(dfs).reset_index(drop=True)\n","    return df\n","\n","train = pd.concat([\n","    add_neighbor_features(train[train[\"set\"]==0]), \n","    add_neighbor_features(train[train[\"set\"]==1]), \n","])\n","test = add_neighbor_features(test)\n","\n","train.head(1)"]},{"cell_type":"markdown","metadata":{"id":"LqqIg-885J3K"},"source":["# Create Target"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftbdH97klAkQ","outputId":"3a49dd42-203b-4117-8312-2e681ec41dd5","trusted":true},"outputs":[],"source":["for i in range(CFG.n_neighbors):\n","    train.loc[train[CFG.target]==train[f\"near_target_{i}\"], \"target\"] = i\n","train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-X97ptgolAkR","outputId":"5d2c9c77-d61d-43a3-93cb-baad6f917b01","trusted":true},"outputs":[],"source":["plt.hist(train[\"target\"], bins=sorted(train[\"target\"].unique()))\n","plt.grid()\n","plt.xlabel(\"target\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Check Maximum Score"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_id2poi(input_df: pd.DataFrame) -> dict:\n","    return dict(zip(input_df['id'], input_df['point_of_interest']))\n","\n","def get_poi2ids(input_df: pd.DataFrame) -> dict:\n","    return input_df.groupby('point_of_interest')['id'].apply(set).to_dict()\n","\n","def get_score(input_df: pd.DataFrame):\n","    scores = []\n","    for id_str, matches in zip(input_df['id'].to_numpy(), input_df['matches'].to_numpy()):\n","        targets = poi2ids[id2poi[id_str]]\n","        preds = set(matches.split())\n","        score = len((targets & preds)) / len((targets | preds))\n","        scores.append(score)\n","    scores = np.array(scores)\n","    return scores.mean()\n","\n","id2poi = get_id2poi(train)\n","poi2ids = get_poi2ids(train)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["scores = []\n","\n","train[\"matches\"] = \"\"\n","for i in tqdm(range(CFG.n_neighbors)):\n","    idx = train[CFG.target]==train[f\"near_target_{i}\"]\n","    train.loc[idx, \"matches\"] += \" \" + train.loc[idx, f\"near_id_{i}\"]\n","    scores.append(get_score(train))\n","train[\"mathces\"] = None"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.subplots(figsize=(8, 3), facecolor=\"white\")\n","plt.plot(range(CFG.n_neighbors), scores, marker=\"o\")\n","plt.grid()\n","plt.xlabel(\"# of candidates\")\n","plt.ylabel(\"Maximum Score\")\n","plt.ylim([0.6, 1.0])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["del train\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"6k59Vk9d5Pmx"},"source":["# Feature Engineering"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%load_ext Cython"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%cython\n","def LCS(str S, str T):\n","    cdef int i, j\n","    cdef list dp = [[0] * (len(T) + 1) for _ in range(len(S) + 1)]\n","    for i in range(len(S)):\n","        for j in range(len(T)):\n","            dp[i + 1][j + 1] = max(dp[i][j] + (S[i] == T[j]), dp[i + 1][j], dp[i][j + 1], dp[i + 1][j + 1])\n","    return dp[len(S)][len(T)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"elWgtrbalAkS","outputId":"f9e3d5d6-ff3c-4b66-c071-076318eebd59","trusted":true},"outputs":[],"source":["import Levenshtein\n","import difflib\n","\n","def _add_distance_features(args):\n","    _, df = args\n","\n","    columns = ['name', 'address', 'city', 'state',\n","           'zip', 'country', 'url', 'phone', 'categories']\n","\n","    for i in tqdm(range(CFG.n_neighbors)):\n","        for c in columns:\n","            geshs = []\n","            levens = []\n","            jaros = []\n","            lcss = []\n","            for str1, str2 in df[[f\"near_{c}_0\", f\"near_{c}_{i}\"]].values.astype(str):\n","                if str1==str1 and str2==str2:\n","                    geshs.append(difflib.SequenceMatcher(None, str1, str2).ratio())\n","                    levens.append(Levenshtein.distance(str1, str2))\n","                    jaros.append(Levenshtein.jaro_winkler(str1, str2))\n","                    lcss.append(LCS(str(str1), str(str2)))\n","                else:\n","                    geshs.append(-1)\n","                    levens.append(-1)\n","                    jaros.append(-1)\n","            df[f\"near_{c}_{i}_gesh\"] = geshs\n","            df[f\"near_{c}_{i}_leven\"] = levens\n","            df[f\"near_{c}_{i}_jaro\"] = jaros\n","            df[f\"near_{c}_{i}_lcs\"] = lcss\n","            \n","            if not c in ['country', \"phone\", \"zip\"]:\n","                df[f\"near_{c}_{i}_len\"] = df[f\"near_{c}_{i}\"].astype(str).map(len)\n","                df[f\"near_{c}_{i}_nleven\"] = df[f\"near_{c}_{i}_leven\"] / df[[f\"near_{c}_{i}_len\", f\"near_{c}_0_len\"]].max(axis=1)\n","                df[f\"near_{c}_{i}_nlcsi\"] = df[f\"near_{c}_{i}_lcs\"] / df[f\"near_{c}_{i}_len\"]\n","                df[f\"near_{c}_{i}_nlcs0\"] = df[f\"near_{c}_{i}_lcs\"] / df[f\"near_{c}_0_len\"]\n","    return df\n","\n","\n","def add_distance_features(df):\n","    processes = multiprocessing.cpu_count()\n","    with multiprocessing.Pool(processes=processes) as pool:\n","        dfs = pool.imap_unordered(_add_distance_features, df.groupby('country'))\n","        dfs = tqdm(dfs)\n","        dfs = list(dfs)\n","    df = pd.concat(dfs)\n","    return df\n","\n","# train = add_distance_features(train)\n","test = add_distance_features(test)"]},{"cell_type":"markdown","metadata":{"id":"Q3HV5kfs6saZ"},"source":["# Delete Unusing Columns (just for avoiding OOM)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHMG8t1UlAkT","outputId":"9c06b154-1276-4069-d21a-7c48907b98dc","trusted":true},"outputs":[],"source":["features = []\n","\n","columns = ['name', 'address', 'city', 'state',\n","       'zip', 'country', 'url', 'phone', 'categories']\n","for i in tqdm(range(CFG.n_neighbors)):\n","    features.append(f\"d_near_{i}\")\n","    for c in columns:        \n","        features += [f\"near_{c}_{i}_gesh\", f\"near_{c}_{i}_jaro\", f\"near_{c}_{i}_lcs\"]\n","        if c in ['country', \"phone\", \"zip\"]:\n","            features += [f\"near_{c}_{i}_leven\"]\n","        else:\n","            features += [f\"near_{c}_{i}_len\", f\"near_{c}_{i}_nleven\", f\"near_{c}_{i}_nlcsi\", f\"near_{c}_{i}_nlcs0\"]\n","\n","for f in features:\n","#     assert f in train.columns\n","    if f not in test.columns:\n","        test[f] = np.nan\n","\n","# print(features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aKSy9cc3lAkT","outputId":"4d1e8ccb-8d7f-454e-cb15-f1cb8693af74","trusted":true},"outputs":[],"source":["# train = train[features + [CFG.target, \"target\", \"id\"] + [f\"near_id_{i}\" for i in range(CFG.n_neighbors)]]\n","test = test[features + [\"id\"] + [f\"near_id_{i}\" for i in range(CFG.n_neighbors)]]\n","\n","# train[features] = train[features].astype(np.float16)\n","test[features] = test[features].astype(np.float16)\n","\n","# train[\"target\"] = train[\"target\"].fillna(0)\n","\n","# train.reset_index(drop=True, inplace=True)\n","test.reset_index(drop=True, inplace=True)\n","\n","for _ in range(5):\n","    gc.collect()\n","\n","# train.info()"]},{"cell_type":"markdown","metadata":{"id":"yduGPkpC6y4X"},"source":["# Split Folds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7euwk2q7ly5Y","outputId":"1e1f8c10-0523-4a37-d1fc-9d350cc96ec5","trusted":true},"outputs":[],"source":["# kf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)\n","# for i, (trn_idx, val_idx) in tqdm(enumerate(kf.split(train, train[\"target\"], train[\"target\"]))):\n","#     train.loc[val_idx, \"fold\"] = i"]},{"cell_type":"markdown","metadata":{"id":"qknhwIvndmJ_"},"source":["# Model Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iLKg1PSWlAkU","trusted":true},"outputs":[],"source":["import lightgbm as lgbm\n","\n","def fit_lgbm(X, y, params=None, es_rounds=20, seed=42, N_SPLITS=5, \n","             n_class=None, model_dir=None, folds=None):\n","    models = []\n","    oof = np.zeros((len(y), n_class), dtype=np.float64)\n","    \n","    for i in tqdm(range(CFG.n_splits)):\n","        print(f\"== fold {i} ==\")\n","        trn_idx = folds!=i\n","        val_idx = folds==i\n","        X_train, y_train = X[trn_idx], y.iloc[trn_idx]\n","        X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n","\n","        if model_dir is None:\n","            model = lgbm.LGBMClassifier(**params)\n","            model.fit(\n","                X_train, y_train, \n","                eval_set=[(X_valid, y_valid)],  \n","                early_stopping_rounds=es_rounds, \n","                eval_metric='logloss',  \n","    #             verbose=-1)\n","                verbose=50)\n","        else:\n","            with open(f'{model_dir}/lgbm_fold{i}.pkl', 'rb') as f:\n","                model = pickle.load(f)\n","            \n","        pred = model.predict_proba(X_valid)\n","        oof[val_idx] = pred\n","        models.append(model)\n","        \n","        file = f'lgbm_fold{i}.pkl'\n","        pickle.dump(model, open(file, 'wb'))\n","        print()\n","\n","    cv = (oof.argmax(axis=-1) == y).mean()\n","    print(f\"CV-accuracy: {cv}\")\n","\n","    return oof, models\n","\n","def inference_lgbm(models, feat_df):\n","    pred = np.array([model.predict_proba(feat_df) for model in models])\n","    pred = np.mean(pred, axis=0)\n","    return pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y22l2kyLlAkV","outputId":"c284471a-0dd7-4d4b-aa98-82378d2f4b32","trusted":true},"outputs":[],"source":["params = {\n","    'objective': \"logloss\",\n","    'learning_rate': 0.2,\n","    'reg_alpha': 0.1,\n","    'reg_lambda': 0.1,\n","    'random_state': 42,\n","\n","    'max_depth': 7,   \n","    'num_leaves': 35, \n","    'n_estimators': 1000000, \n","    \"colsample_bytree\": 0.9,\n","}\n","\n","# oof, models = fit_lgbm(train[features], train[\"target\"].astype(int), \n","#                        params=params, n_class=int(train[\"target\"].max() + 1), \n","#                        N_SPLITS=CFG.n_splits, folds=train[\"fold\"].values)\n","\n","models = [joblib.load(f'../input/foursquare-exp009/lgbm_fold{i}.pkl') for i in range(CFG.n_splits)]\n","pred = inference_lgbm(models, test[features])"]},{"cell_type":"markdown","metadata":{},"source":["# Check CV"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yHFNkcnglAkW","outputId":"b886a788-4f08-468b-8050-17e92da005ca","trusted":true},"outputs":[],"source":["# near_ids = train[[f\"near_id_{i}\" for i in range(CFG.n_neighbors)]].values\n","\n","# matches = []\n","# for id, ps, ids in tqdm(zip(train[\"id\"], oof, near_ids)):\n","#     idx = np.argmax(ps)\n","#     if idx > 0 and ids[idx]==ids[idx]:\n","#         matches.append(id + \" \" + ids[idx])\n","#     else:\n","#         matches.append(id)\n","# train[\"matches\"] = matches\n","# print(f\"CV: {get_score(train):.6f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["near_ids = test[[f\"near_id_{i}\" for i in range(CFG.n_neighbors)]].values\n","\n","matches = []\n","for id, ps, ids in tqdm(zip(test[\"id\"], pred, near_ids)):\n","    idx = np.argmax(ps)\n","    if idx > 0 and ids[idx]==ids[idx]:\n","        matches.append(id + \" \" + ids[idx])\n","    else:\n","        matches.append(id)\n","test[\"matches\"] = matches"]},{"cell_type":"markdown","metadata":{},"source":["# Check Feature Importances"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o7YqLSXPlAkX","outputId":"11bfa4d9-e19a-4934-f3de-8dacf74f4a18","trusted":true},"outputs":[],"source":["def plot_importances(models):\n","    importance_df = pd.DataFrame(models[0].feature_importances_, \n","                                 index=features, \n","                                 columns=['importance'])\\\n","                        .sort_values(\"importance\", ascending=False)\n","\n","    plt.subplots(figsize=(len(features) // 4, 5))\n","    plt.bar(importance_df.index, importance_df.importance)\n","    plt.grid()\n","    plt.xticks(rotation=90)\n","    plt.ylabel(\"importance\")\n","    plt.tight_layout()\n","    plt.show()\n","\n","plot_importances(models)"]},{"cell_type":"markdown","metadata":{},"source":["# Simple Post-Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UffaiHGelAkW","trusted":true},"outputs":[],"source":["def postprocess(df):\n","    id2match = dict(zip(df[\"id\"].values, df[\"matches\"].str.split()))\n","\n","    for match in tqdm(df[\"matches\"]):\n","        match = match.split()\n","        if len(match) == 1:        \n","            continue\n","\n","        base = match[0]\n","        for m in match[1:]:\n","            if not base in id2match[m]:\n","                id2match[m].append(base)\n","    df[\"matches\"] = df[\"id\"].map(id2match).map(\" \".join)\n","    return df \n","\n","#train = postprocess(train)\n","test = postprocess(test)\n","# print(f\"CV: {get_score(train):.6f}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Submit"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ssub = pd.read_csv(\"../input/foursquare-location-matching/sample_submission.csv\")\n","ssub = ssub.drop(columns=\"matches\")\n","ssub = ssub.merge(test[[\"id\", \"matches\"]], on=\"id\")\n","ssub.to_csv(\"submission.csv\", index=False)\n","\n","ssub.head()"]}],"metadata":{"interpreter":{"hash":"14912a5ec1d5b093c11c82e3b42baba6b47c23ed9d4bc1719570c1ba562393aa"},"kernelspec":{"display_name":"Python 3.8.10 ('HW3-9xnMMrK4')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
